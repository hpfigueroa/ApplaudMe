{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages and setting up plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rc('xtick', labelsize=20) \n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('legend', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['clap_count', 'detected_language', 'image_count', 'post_creatorId',\n",
    "#       'post_date', 'post_id', 'post_link_count', 'post_publication_id',\n",
    "#       'post_tags', 'post_url', 'publication_follower_count', 'read_time',\n",
    "#       'response_count', 'subtitle', 'title', 'unique_slug', 'word_count',\n",
    "#       'archive_date', 'full_text', 'clap_target', 'y', 'FK_grade', 'com',\n",
    "#       'neg', 'neu', 'pos']\n",
    "trainingdf = train_df.drop(['clap_count', 'detected_language', 'post_creatorId',\n",
    "       'post_date', 'post_id', 'post_publication_id', \n",
    "       'post_tags', 'post_url', \n",
    "       'response_count', 'subtitle', 'title', 'unique_slug', 'word_count',\n",
    "       'archive_date', 'full_text', 'clap_target_q20', 'clap_target_q80', 'clap_target_q90',\n",
    "                           'y80','y90','FK_grade','neg','pos'],axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = trainingdf.values\n",
    "y = train_df['y80'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Machine Learning\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "h = .02  # step size in the mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight.compute_class_weight('balanced',classes=np.array([0,1]),y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qScaler = QuantileTransformer(output_distribution='uniform')\n",
    "stdScaler = StandardScaler() \n",
    "X = qScaler.fit_transform(X_raw)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "names = [\"Logistic Reg\", \"Naive Bayes\", \"Linear SVM\", \"Random Forest\"]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(class_weight='balanced'),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel=\"rbf\",class_weight='balanced',probability=True),\n",
    "    RandomForestClassifier(max_depth=3, n_estimators=20, max_features=3, class_weight='balanced')]\n",
    "\n",
    "models = [clf.fit(X_train, y_train) for clf in classifiers]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [clf.score(X_test, y_test) for clf in models]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "for clf in models:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(names[ii],recall_score(y_test, y_pred))\n",
    "    ii=ii+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "for clf in models:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(names[ii],precision_recall_fscore_support(y_test, y_pred))\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "for clf in models:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(names[ii],f1_score(y_test, y_pred))\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "ii=0\n",
    "for clf in models:\n",
    "    prob_y = clf.predict_proba(X)\n",
    "    prob_y = [p[1] for p in prob_y]\n",
    "    print(names[ii],roc_auc_score(y, prob_y))\n",
    "    ii=ii+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "clf = models[3]\n",
    "#clf1 = SVC(kernel=\"linear\",probability=True)\n",
    "#clf1 = RandomForestClassifier(max_depth=5, n_estimators=20, max_features=1)\n",
    "#clf1 = GradientBoostingClassifier(n_estimators=20)\n",
    "#for i in range(2,4):\n",
    "    #X_train, X_test, y_train, y_test = \\\n",
    "    #train_test_split(X, y, test_size=i/10, random_state=42)\n",
    "\n",
    "    #clf.fit(X_train, y_train)\n",
    "    #score = clf.score(X_test, y_test)\n",
    "    #print(i/10,'score',score)\n",
    "    #probas_ = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "    #%%\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "i=1\n",
    "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('roc',roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold (AUC = %0.2f)' % (roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=.8)\n",
    "\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.savefig('ROC.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "y_pred = clf.predict(X_test)\n",
    "cnf_matrix  = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Success','Needs Work']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the normalized confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tr_matrix = cnf_matrix.copy()\n",
    "tr_matrix[0][0] = cnf_matrix[1][1]#.transpose()\n",
    "tr_matrix[0][1] = cnf_matrix[1][0]\n",
    "tr_matrix[1][0] = cnf_matrix[0][1]#.transpose()\n",
    "tr_matrix[1][1] = cnf_matrix[0][0]\n",
    "#cnf_matrix = cnf_matrix.transpose()\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(tr_matrix, classes=class_names, \n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.savefig('confusion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trainingdf.columns\n",
    "toppostdf80 = train_df.drop(train_df.loc[train_df.y80==0].index, axis=0).copy()\n",
    "toppostdf90 = train_df.drop(train_df.loc[train_df.y90==0].index, axis=0).copy()\n",
    "print(len(toppostdf80))\n",
    "print(len(toppostdf90))\n",
    "X80_raw = toppostdf80.drop(['clap_count', 'detected_language', 'post_creatorId',\n",
    "       'post_date', 'post_id', 'post_publication_id', \n",
    "       'post_tags', 'post_url', \n",
    "       'response_count', 'subtitle', 'title', 'unique_slug', 'word_count',\n",
    "       'archive_date', 'full_text', 'clap_target_q20', 'clap_target_q80',\n",
    "                            'clap_target_q90','y80','y90','FK_grade','neg','pos'],axis=1).values\n",
    "X90_raw = toppostdf90.drop(['clap_count', 'detected_language', 'post_creatorId',\n",
    "       'post_date', 'post_id', 'post_publication_id', \n",
    "       'post_tags', 'post_url', \n",
    "       'response_count', 'subtitle', 'title', 'unique_slug', 'word_count',\n",
    "       'archive_date', 'full_text', 'clap_target_q20', 'clap_target_q80',\n",
    "                            'clap_target_q90','y80','y90','FK_grade','neg','pos'],axis=1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X90_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X80 = qScaler.transform(X80_raw).mean(axis=0)\n",
    "X80 = qScaler.transform([X80_raw.mean(axis=0)])\n",
    "#X90 = qScaler.transform(X90_raw).mean(axis=0)\n",
    "X90 = qScaler.transform([X90_raw.mean(axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'clf.pkl') \n",
    "joblib.dump(qScaler,'qscl.pkl')\n",
    "pickle.dump(X80,open('X80.p', \"wb\" ))\n",
    "pickle.dump(X90,open('X90.p', \"wb\" ))\n",
    "pickle.dump(feature_ranks,open('feature_ranks.p', \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "top_articles = trainingdf.mean()\n",
    "#%%\n",
    "X_top = stdScl.transform([top_articles.values])\n",
    "#y_predtop = clf.predict(X_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks = pd.DataFrame(\n",
    "    clf.feature_importances_.T.ravel()[:len(features)],columns=['fval'],\n",
    "    index=features\n",
    ")\n",
    "feature_ranks['order'] = range(len(feature_ranks))\n",
    "print(feature_ranks.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_indexes = feature_ranks.sort_values(by='fval',ascending=False)['order'].values\n",
    "#predictive_features\n",
    "# List of meta features that were most predictive of funded projects\n",
    "predictive_features = ['publication followers', 'read time', 'grade level',\n",
    "                       'number of links', 'neutrality','sentiment','number of images','length title-subtitle','number of questions']\n",
    "predictive_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks1 = pd.Series(\n",
    "    models[2].coef_.T.ravel()[:len(features)],\n",
    "    index=features\n",
    ")\n",
    "print(feature_ranks1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted score of the meta features of a project\n",
    "user_article_score = np.multiply(\n",
    "    [X[3500]],\n",
    "    feature_ranks['fval'].values\n",
    ")\n",
    "#%%\n",
    "# Compute the weighted score of the meta features of the average top project\n",
    "top80_article_score = np.multiply(\n",
    "    X80,\n",
    "    feature_ranks['fval'].values\n",
    ")\n",
    "top90_article_score = np.multiply(\n",
    "    X90,\n",
    "    feature_ranks['fval'].values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw[3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X80_raw.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qScaler.transform([X_raw[230]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qScaler.transform([X80_raw.mean(axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top80_article_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Combine the weighted scores into a single DataFrame\n",
    "messy = pd.DataFrame([user_article_score[0,predictive_indexes], top80_article_score[0,predictive_indexes],top90_article_score[0,predictive_indexes]],\n",
    "                     index=['Your article', 'Top 20% articles', 'Top 10% articles']).T.reset_index()\n",
    "#%%\n",
    "# Transform the combined data into tidy format\n",
    "tidy = pd.melt(\n",
    "    messy,\n",
    "    id_vars='index',\n",
    "    value_vars=['Your article', 'Top 20% articles', 'Top 10% articles'],\n",
    "    var_name=' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%%\n",
    "# Draw a grouped bar plot of the weighted scores\n",
    "fontsize = 12\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.rc('xtick', labelsize=fontsize)\n",
    "plt.rc('ytick', labelsize=fontsize)\n",
    "plt.rc('legend', fontsize=fontsize)\n",
    "sns.factorplot(\n",
    "    data=tidy,\n",
    "    y='index',\n",
    "    x='value',\n",
    "    hue=' ',\n",
    "    kind='bar',\n",
    "    size=4,\n",
    "    aspect=2,\n",
    "    palette='Set1',\n",
    "    orient='h',\n",
    "    legend_out=False\n",
    ").set(\n",
    "    xlabel='score',\n",
    "    ylabel='features',\n",
    "    xticks=[]\n",
    ")\n",
    "#%%\n",
    "plt.yticks(range(len(predictive_features)),predictive_features)\n",
    "plt.savefig('Features.png')\n",
    "#%%\n",
    "# Re-label the y-axis and reposition the legend\n",
    "#labels = trainingdf.columns\n",
    "#['hyperlinks', 'images', 'innovation words', 'exclamation marks','bolded text', 'length of description']\n",
    "#plt.yticks(trainingdf.columns.values)\n",
    "#plt.yticks(predictive_features)\n",
    "\n",
    "#fig.ax.legend(loc='lower right');\n",
    "plt.savefig('figure.png', bbox_inches='tight', dpi=300);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X[3500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(models[3].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainingdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Fail','Success']\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import lime.lime_tabular\n",
    "class_names = ['Fail','Success']\n",
    "X_raw = X\n",
    "#from lime.lime_text import LimeTextExplainer\n",
    "import lime.lime_tabular\n",
    "explainer1 = lime.lime_tabular.LimeTabularExplainer(X, feature_names=trainingdf.columns, class_names=['fail','success'], discretize_continuous=True)\n",
    "X1 = qScaler.transform(X_raw)\n",
    "y_pred = models[3].predict(X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2000\n",
    "#exp = explainer.explain_instance(X, clf.predict_proba, num_features=6)\n",
    "exp = explainer1.explain_instance(X1[i], models[3].predict_proba, num_features=4)\n",
    "#print('Document id: %d' % )\n",
    "print('Probability =', models[3].predict_proba([X1[i]]))\n",
    "print('True class: %s' % y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdf.index = range(len(trainingdf))\n",
    "trainingdf.loc[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X[230]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,2))\n",
    "sns.distplot(train_df.loc[train_df['y_train']==False,'neg'], bins = np.linspace(0,1,100))\n",
    "sns.distplot(train_df.loc[train_df['y_train'],'neg'], bins = np.linspace(0,1,100))\n",
    "plt.legend(['Fail','Success'])\n",
    "#plt.xlim([0,1])\n",
    "plt.savefig('negative.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,2))\n",
    "sns.distplot(train_df.loc[train_df['y_train']==False,'neu'], np.linspace(0,1,50))\n",
    "sns.distplot(train_df.loc[train_df['y_train'],'neu'], np.linspace(0,1,50))\n",
    "plt.legend(['Fail','Success'])\n",
    "plt.xlim([0,1])\n",
    "plt.savefig('neutral.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,2))\n",
    "#sns.distplot(train_df.loc[train_df['y_train']==False,'com'], np.linspace(0,1,50))\n",
    "sns.distplot(train_df.loc[train_df['y_train']==False,'com'])\n",
    "\n",
    "#sns.distplot(train_df.loc[train_df['y_train'],'com'], np.linspace(0,1,50))\n",
    "sns.distplot(train_df.loc[train_df['y_train'],'com'])\n",
    "plt.legend(['Fail','Success'])\n",
    "#plt.xlim([0,1])\n",
    "plt.savefig('neutral.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_post_df.loc[3000,'publication_follower_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_post_df.loc[3000,'image_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_post_df.loc[3000,'post_link_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0 = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0.class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_order = ['number of images','number of links','publication followers', 'read time', 'grade level',\n",
    "                       'sentiment','neutrality','number of questions','length title-subtitle']\n",
    "plt.bar(range(9),clf0.coef_[0])\n",
    "plt.xticks(range(9),original_order,rotation='vertical')\n",
    "\n",
    "plt.savefig('LR_coefficients.png',bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(9),clf.feature_importances_)\n",
    "plt.xticks(range(9),original_order,rotation='vertical')\n",
    "plt.savefig('RF_coefficients.png',bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
